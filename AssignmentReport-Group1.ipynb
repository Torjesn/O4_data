{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "Intersection over union is how much of the area covered by either bounding box (union) is covered by both bounding boxes (intersection).\n",
    "\n",
    "In the picture under, we have two bounding boxes, red and blue. The intersection is the area covered by both, in green. The union is the area covered by at least one of them, meaning the green area + the purple area. \n",
    "If the magnitude of the green area is G and magnitude of the purple area is P, and \n",
    "$IoU =  \\frac{intersection}{Union}$, then\n",
    "$IoU = \\frac{G}{G+P}$\n",
    "\n",
    "\n",
    "\n",
    "![](pics/1a_.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "TP = true positive\n",
    "FP = false positive\n",
    "FN = false negative\n",
    "\n",
    "$Precision = \\frac{TP}{TP+FP}$\n",
    "\n",
    "$Recall = \\frac{TP}{TP+FN}$\n",
    "\n",
    "A true positive is a positive that consides enough with the a ground truth to be considered correct. \n",
    "A false positive is a positive that does not conside enough with the a ground truth to be considered correct. \n",
    "\n",
    "## task 1c)\n",
    "Used Geogebra to find the interpolated curves:\n",
    "The mAP is the area times 10/11, since the rectangle of each recall level is 0.1 in length.\n",
    "The red dots are the givel values, the blue are the extra interpolated ones. \n",
    "\n",
    "### First series:\n",
    "![](pics/1c1_a.png)\n",
    "Area = 0.7 -> AP = 7/11\n",
    "\n",
    "### Second series:\n",
    "![](pics/1c2_a.png)\n",
    "Area = 0.7 -> AP = 7/11\n",
    "\n",
    "### mAP:\n",
    "mAP = (AP1+AP2)/2 = = 7/11 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "non-maximum suppression (nms)\n",
    "\n",
    "### Task 3b)\n",
    "False -> Deeper layers -> lower resolution -> bigger objects.\n",
    "The statement is false, as deeper layers have lower resolution, and is therefore able to detect bigger objects.\n",
    "\n",
    "\n",
    "### Task 3c)\n",
    "The use different bounding box aspect ratios to get different shapes in the bounding boxes, for instance some with height bigger than width, or the opposite. This is to be able to look for different kinds of shapes, as for instance a car and a pedestrian usually fit into different bounding box shapes. The aspects assures that default bounding boxes of different shapes are utilized\n",
    "\n",
    "\n",
    "### Task 3d)\n",
    "Main difference(s) between YOLO and SSD.\n",
    "YOLO uses a FCN layer to classify after the initial feature extraction, and uses a single scale feature map in the end to classify both class and bounding box, while SSD uses multiple layers of convolution afer the initial feature extraction, and classifies some bounding boxes with classes for each convolution layer. This results in many more predictions than in the YOLO, and also greater accuracy\n",
    "\n",
    "\n",
    "### Task 3e)\n",
    "We have one anchor location per input value.\n",
    "This gives us 38x38 anchor locations, and 6 anchors boxes per location, meaning 8664 anchor boxes.\n",
    "\n",
    "\n",
    "### Task 3f)\n",
    "Same as last task, the sum of the input size times number of boxes created per location.\n",
    "(38*38+19*19+10*10+5*5+3*3+1*1)*6 = 11640 anchor boxes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "\n",
    "FILL IN ANSWER. \n",
    "\n",
    "## Task 4c)\n",
    "FILL IN ANSWER. \n",
    "\n",
    "\n",
    "## Task 4d)\n",
    "FILL IN ANSWER. \n",
    "\n",
    "\n",
    "## Task 4e)\n",
    "FILL IN ANSWER. \n",
    "\n",
    "\n",
    "## Task 4f)\n",
    "FILL IN ANSWER. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
